#!/bin/bash

set -e -o pipefail

LOG_DIR="/var/log/terraform-provisioning"
LOG_FILE="$LOG_DIR/bootstrap.log"

# Create a log directory and make it owned by the SSH user
sudo mkdir -p "$LOG_DIR"
sudo chown $(whoami):$(whoami) "$LOG_DIR"
touch "$LOG_FILE"

# Function for timestamped logging
log_with_timestamp() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

# Redirect all stdout/stderr into the log (and the console)
exec &> >(tee -a "$LOG_FILE")

log_with_timestamp "=== Terraform Remote-Exec Bootstrap ==="
log_with_timestamp "Run started at: $(date)"

log_with_timestamp "--- Running Remote-Exec Bootstrap Script ---"
log_with_timestamp "Waiting for cloud-init finalization..."
timeout 60 sudo cloud-init status --wait || log_with_timestamp "WARN: cloud-init wait timed out, proceeding anyway..."

log_with_timestamp "Fetching runtime values..."
INSTANCE_PRIVATE_IP=$(curl -fsSL http://169.254.169.254/latest/meta-data/local-ipv4)
if [ -z "$INSTANCE_PRIVATE_IP" ]; then 
    log_with_timestamp "FATAL: Failed to get instance IP"
    exit 1
fi
log_with_timestamp "Got Instance IP: $INSTANCE_PRIVATE_IP"

# Move Config
log_with_timestamp "Moving final kubeadm config to /etc/kubeadm/"
sudo mkdir -p /etc/kubeadm
sudo mv /tmp/kubeadm-config-rendered.yaml /etc/kubeadm/kubeadm-config.yaml
sudo chown root:root /etc/kubeadm/kubeadm-config.yaml
log_with_timestamp "Kubeadm config moved successfully"

# Run kubeadm init (idempotently)
log_with_timestamp "Checking for existing admin.conf..."
if [ -f /etc/kubernetes/admin.conf ]; then
    log_with_timestamp "kubeadm init already completed."
    # Regenerate join info just in case
    log_with_timestam "Ensuring join commands are generated..."
    sudo kubeadm token create --print-join-command > /tmp/kubeadm_join_worker.sh || log_with_timestamp "WARN: Failed to create token"
    sudo chmod +x /tmp/kubeadm_join_worker.sh || true
    sudo kubeadm init phase upload-certs --upload-certs > /tmp/kube_cert_key_unsafe.txt || log_with_timestamp "WARN: Failed to upload certs"
    sudo tail -n 1 /tmp/kube_cert_key_unsafe.txt > /tmp/kube_cert_key_only.txt || true
    log_with_timestamp "Join command and cert key generation attempted."
else
    log_with_timestamp "Running kubeadm reset just in case..."
    sudo kubeadm reset -f || log_with_timestamp "kubeadm reset failed or nothing to reset, proceeding..."
    
    log_with_timestamp "Starting kubeadm init..."
    log_with_timestamp "Config file contents:"
    sudo cat /etc/kubeadm/kubeadm-config.yaml
    
    log_with_timestamp "Running kubeadm init with verbose output..."
    if sudo kubeadm init --config /etc/kubeadm/kubeadm-config.yaml --upload-certs --v=5; then
        log_with_timestamp "kubeadm init completed successfully"
    else
        log_with_timestamp "FATAL: kubeadm init failed"
        exit 1
    fi

    # Generate Join Commands AFTER successful init
    log_with_timestamp "kubeadm init successful. Generating join commands..."
    sudo kubeadm token create --print-join-command > /tmp/kubeadm_join_worker.sh
    sudo chmod +x /tmp/kubeadm_join_worker.sh
    sudo kubeadm init phase upload-certs --upload-certs > /tmp/kube_cert_key_unsafe.txt
    sudo tail -n 1 /tmp/kube_cert_key_unsafe.txt > /tmp/kube_cert_key_only.txt
    log_with_timestamp "Join command and cert key generated."
fi

# Verify cluster is responding
log_with_timestamp "Verifying cluster is responding..."
sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf cluster-info
sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf get nodes

# Install CNI plugin (Calico)
log_with_timestamp "Installing Calico CNI..."

# Define wait parameters
WAIT_TIMEOUT=300 # 5 minutes timeout
WAIT_INTERVAL=10 # Check every 10 seconds

CALICO_URL="https://docs.projectcalico.org/manifests/calico.yaml"
log_with_timestamp "Applying Calico manifests from $CALICO_URL"

if sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf apply -f "$CALICO_URL"; then
    log_with_timestamp "Applied Calico manifests successfully"
else
    log_with_timestamp "FATAL: Failed to apply Calico manifests from $CALICO_URL"
    exit 1
fi

# Wait for CNI (Calico pods) to be ready
log_with_timestamp "Waiting for CNI (Calico pods) to be ready..."

WAIT_TIMEOUT_CNI=300 # 5 minutes timeout
WAIT_INTERVAL_CNI=10 # Check every 10 seconds
ELAPSED_CNI=0

# Check calico pods status
while true; do
    log_with_timestamp "Checking Calico pod status ($ELAPSED_CNI s / $WAIT_TIMEOUT_CNI s)..."
    
    # Get current pod status for debugging
    sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-system get pods -l k8s-app=calico-node || true
    sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-system get pods -l k8s-app=calico-kube-controllers || true
    
    # Check if calico pods are running
    CALICO_NODE_READY=$(sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-system get pods -l k8s-app=calico-node --field-selector=status.phase=Running --no-headers 2>/dev/null | wc -l)
    CALICO_CONTROLLER_READY=$(sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-system get pods -l k8s-app=calico-kube-controllers --field-selector=status.phase=Running --no-headers 2>/dev/null | wc -l)
    
    log_with_timestamp "Calico nodes ready: $CALICO_NODE_READY, Controllers ready: $CALICO_CONTROLLER_READY"
    
    if [ "$CALICO_NODE_READY" -gt 0 ] && [ "$CALICO_CONTROLLER_READY" -gt 0 ]; then
        log_with_timestamp "CNI (Calico) is ready."
        break
    fi
    
    if [ "$ELAPSED_CNI" -ge "$WAIT_TIMEOUT_CNI" ]; then 
        log_with_timestamp "FATAL: Timeout waiting for Calico pods to be ready."
        exit 1
    fi
    
    sleep "$WAIT_INTERVAL_CNI"
    ELAPSED_CNI=$((ELAPSED_CNI + WAIT_INTERVAL_CNI))
done

# Wait for node to be ready
log_with_timestamp "Waiting for node to be ready..."
sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf wait --for=condition=Ready nodes --all --timeout=300s

# --- Setup kubectl config for user ${k8s_user} ---
log_with_timestamp "Setting up kubectl config for user ${k8s_user}..."
TARGET_K8S_USER_FOR_CONFIG="${k8s_user}"

# --- ADD DEBUGGING ---
log_with_timestamp "DEBUG: Running as user: $(whoami)"
log_with_timestamp "DEBUG: Checking existence of user: $TARGET_K8S_USER_FOR_CONFIG"
log_with_timestamp "DEBUG: Running 'id $TARGET_K8S_USER_FOR_CONFIG' command..."

if id "$TARGET_K8S_USER_FOR_CONFIG" >/dev/null 2>&1; then
    ID_EXIT_CODE=0
    log_with_timestamp "DEBUG: User $TARGET_K8S_USER_FOR_CONFIG exists"
else
    ID_EXIT_CODE=$?
    log_with_timestamp "DEBUG: User $TARGET_K8S_USER_FOR_CONFIG does not exist (exit code: $ID_EXIT_CODE)"
fi

# Check using the captured exit code
if [ $ID_EXIT_CODE -ne 0 ]; then
    log_with_timestamp "Warning: User $TARGET_K8S_USER_FOR_CONFIG does not exist! Skipping user kubectl config setup."
else
    # User exists, proceed with setup
    KUBE_DIR="/home/$TARGET_K8S_USER_FOR_CONFIG/.kube"
    KUBE_CONFIG="$KUBE_DIR/config"
    ADMIN_CONFIG_PATH="/etc/kubernetes/admin.conf"
    
    log_with_timestamp "Creating directory $KUBE_DIR..."
    sudo mkdir -p "$KUBE_DIR"
    
    log_with_timestamp "Copying admin config to $KUBE_CONFIG..."
    sudo cp "$ADMIN_CONFIG_PATH" "$KUBE_CONFIG"
    
    log_with_timestamp "Setting ownership for $KUBE_DIR..."
    TARGET_UID=$(id -u "$TARGET_K8S_USER_FOR_CONFIG")
    TARGET_GID=$(id -g "$TARGET_K8S_USER_FOR_CONFIG")
    
    if [ -n "$TARGET_UID" ] && [ -n "$TARGET_GID" ]; then
        sudo chown "$TARGET_UID:$TARGET_GID" "$KUBE_DIR"
        sudo chown "$TARGET_UID:$TARGET_GID" "$KUBE_CONFIG"
        log_with_timestamp "Successfully configured kubectl for user $TARGET_K8S_USER_FOR_CONFIG."
    else
        log_with_timestamp "Warning: Could not determine UID/GID for user ${k8s_user}. Skipping chown."
    fi
fi

log_with_timestamp "Creating completion signal file..."
sudo touch /tmp/terraform_bootstrap_complete
log_with_timestamp "Bootstrap provisioner completed successfully!"

# Final verification
log_with_timestamp "Final cluster verification..."
sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf get nodes
sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf get pods -A

log_with_timestamp "-----------------------------------------------------"
log_with_timestamp "Bootstrap provisioner completed successfully!"
log_with_timestamp "-----------------------------------------------------"























