#!/bin/bash

set -e -o pipefail

# --- Logging Setup ---
LOG_DIR="/var/log/terraform-provisioning"
LOG_FILE="$LOG_DIR/controller-setup.log"
touch $LOG_FILE

exec > >(tee -a "$LOG_FILE") 2>&1

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

handle_error() {
    log "ERROR: $1"
    exit 1
}

# Function for timestamped logging
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

# Verify cluster is responding
log "Verifying cluster is responding..."
sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf cluster-info

# Remove conflicting package
apt-get update
apt-get remove -y cnitool-plugins

# Install CNI plugin (Calico)
log "Installing Calico CNI..."

# Define wait parameters
WAIT_TIMEOUT=300 # 5 minutes timeout
WAIT_INTERVAL=10 # Check every 10 seconds

CALICO_URL="https://docs.projectcalico.org/manifests/calico.yaml"
log "Applying Calico manifests from $CALICO_URL"

if sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf apply -f "$CALICO_URL"; then
    log "Applied Calico manifests successfully"
else
    log "FATAL: Failed to apply Calico manifests from $CALICO_URL"
    exit 1
fi

# Wait for CNI (Calico pods) to be ready
log "Waiting for CNI (Calico pods) to be ready..."

WAIT_TIMEOUT_CNI=300 # 5 minutes timeout
WAIT_INTERVAL_CNI=10 # Check every 10 seconds
ELAPSED_CNI=0

# Check calico pods status
while true; do
    log "Checking Calico pod status ($ELAPSED_CNI s / $WAIT_TIMEOUT_CNI s)..."
    
    # Get current pod status for debugging
    sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-system get pods -l k8s-app=calico-node || true
    sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-system get pods -l k8s-app=calico-kube-controllers || true
    
    # Check if calico pods are running
    CALICO_NODE_READY=$(sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-system get pods -l k8s-app=calico-node --field-selector=status.phase=Running --no-headers 2>/dev/null | wc -l)
    CALICO_CONTROLLER_READY=$(sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-system get pods -l k8s-app=calico-kube-controllers --field-selector=status.phase=Running --no-headers 2>/dev/null | wc -l)
    
    log "Calico nodes ready: $CALICO_NODE_READY, Controllers ready: $CALICO_CONTROLLER_READY"
    
    if [ "$CALICO_NODE_READY" -gt 0 ] && [ "$CALICO_CONTROLLER_READY" -gt 0 ]; then
        log "CNI (Calico) is ready."
        break
    fi
    
    if [ "$ELAPSED_CNI" -ge "$WAIT_TIMEOUT_CNI" ]; then 
        log "FATAL: Timeout waiting for Calico pods to be ready."
        exit 1
    fi
    
    sleep "$WAIT_INTERVAL_CNI"
    ELAPSED_CNI=$((ELAPSED_CNI + WAIT_INTERVAL_CNI))
done

# Wait for node to be ready
log "Waiting for node to be ready..."
sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf wait --for=condition=Ready nodes --all --timeout=300s

# --- Setup kubectl config for user ${k8s_user} ---
log "Setting up kubectl config for user ${k8s_user}..."
TARGET_K8S_USER_FOR_CONFIG="${k8s_user}"

# --- ADD DEBUGGING ---
log "DEBUG: Running as user: $(whoami)"
log "DEBUG: Checking existence of user: $TARGET_K8S_USER_FOR_CONFIG"
log "DEBUG: Running 'id $TARGET_K8S_USER_FOR_CONFIG' command..."

if id "$TARGET_K8S_USER_FOR_CONFIG" >/dev/null 2>&1; then
    ID_EXIT_CODE=0
    log "DEBUG: User $TARGET_K8S_USER_FOR_CONFIG exists"
else
    ID_EXIT_CODE=$?
    log "DEBUG: User $TARGET_K8S_USER_FOR_CONFIG does not exist (exit code: $ID_EXIT_CODE)"
fi

# Check using the captured exit code
if [ $ID_EXIT_CODE -ne 0 ]; then
    log "Warning: User $TARGET_K8S_USER_FOR_CONFIG does not exist! Skipping user kubectl config setup."
else
    # User exists, proceed with setup
    KUBE_DIR="/home/$TARGET_K8S_USER_FOR_CONFIG/.kube"
    KUBE_CONFIG="$KUBE_DIR/config"
    ADMIN_CONFIG_PATH="/etc/kubernetes/admin.conf"
    
    log "Creating directory $KUBE_DIR..."
    sudo mkdir -p "$KUBE_DIR"
    
    log "Copying admin config to $KUBE_CONFIG..."
    sudo cp "$ADMIN_CONFIG_PATH" "$KUBE_CONFIG"
    
    log "Setting ownership for $KUBE_DIR..."
    TARGET_UID=$(id -u "$TARGET_K8S_USER_FOR_CONFIG")
    TARGET_GID=$(id -g "$TARGET_K8S_USER_FOR_CONFIG")
    
    if [ -n "$TARGET_UID" ] && [ -n "$TARGET_GID" ]; then
        sudo chown "$TARGET_UID:$TARGET_GID" "$KUBE_DIR"
        sudo chown "$TARGET_UID:$TARGET_GID" "$KUBE_CONFIG"
        log "Successfully configured kubectl for user $TARGET_K8S_USER_FOR_CONFIG."
    else
        log "Warning: Could not determine UID/GID for user ${k8s_user}. Skipping chown."
    fi
fi

log "Creating completion signal file..."
sudo touch /tmp/terraform_bootstrap_complete
log "Bootstrap provisioner completed successfully!"

# Final verification
log "Final cluster verification..."
sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf get nodes
sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf get pods -A

log "-----------------------------------------------------"
log "Bootstrap provisioner completed successfully!"
log "-----------------------------------------------------"























